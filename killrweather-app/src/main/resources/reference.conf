####################################
# KillrWeather Reference Config File #
####################################

killrweather {

  spark.checkpoint.dir = "./tmp"

  cassandra {
    keyspace = "isd_weather_data"
    table.raw = "raw_weather_data"
    table.daily.temperature = "daily_aggregate_temperature"
    table.daily.precipitation = "daily_aggregate_precip"
    table.cumulative.precipitation = "year_cumulative_precip"
    table.sky = "sky_condition_lookup"
    table.stations = "weather_station"
  }
  kafka {
    hosts = [${?KAFKA_HOSTS}]
    group.id = "kafkanode-1"
    topic.raw = "killrweather.raw"
    batch.send.size = 100
  }
  # The raw weather data year range to iterate, within 2000
  # right now not downloading, only using 1 local in /${data.dir}
  data {
    load.path = "./data/load"
    raw {
      year {
        prefix = 200
        start = 5
        end = 5
      }
    }

    daily {
      # Run the daily temp task every 60 minutes
      temperature-task-interval-min = 60
    }
  }

  dispatchers {
    temperature {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        # Min number of threads to cap factor-based parallelism number to
        parallelism-min = 2
        parallelism-max = 2
      }
    }
  }
}

akka {
  # Set to "OFF" to disable logging.
  loglevel = "INFO"
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  actor {
    #provider = "akka.cluster.ClusterActorRefProvider"
  }
  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2551
    }
  }

  #cluster {
  #  seed-nodes = [
  #    "akka.tcp://ClusterSystem@127.0.0.1:2551",
  #    "akka.tcp://ClusterSystem@127.0.0.1:2552"]
  #
  #  auto-down-unreachable-after = 10s
  #}

}